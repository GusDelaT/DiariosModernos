{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCVT0vJcXEE5Y2LfyWFrl8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GusDelaT/DiariosModernos/blob/main/VGG16_GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implementación VGG-16 Diarios Modernos**\n",
        "Primero se debe hacer la instalación de las siguientes librerías que se utilizaran en diferentes partes de la red neuronal para parametrizar de manera precisa. A la vez que simplificar labores de exploración de datos que sean relevantes en el proceso.\n",
        "\n"
      ],
      "metadata": {
        "id": "oW_VeCNZWSJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabula-py\n",
        "!pip install pdf2image\n",
        "!apt-get install poppler-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWIsBCgwmDh6",
        "outputId": "6aefb215-4d3c-4bcf-9210-90215d2e700e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabula-py in /usr/local/lib/python3.11/dist-packages (2.10.0)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.11/dist-packages (from tabula-py) (2.2.2)\n",
            "Requirement already satisfied: numpy>1.24.4 in /usr/local/lib/python3.11/dist-packages (from tabula-py) (1.26.4)\n",
            "Requirement already satisfied: distro in /usr/local/lib/python3.11/dist-packages (from tabula-py) (1.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25.3->tabula-py) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25.3->tabula-py) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->tabula-py) (1.17.0)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.1.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.6 [186 kB]\n",
            "Fetched 186 kB in 1s (326 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 124561 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.6_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from zipfile import ZipFile\n",
        "import os,glob\n",
        "import cv2\n",
        "from keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib as plt\n",
        "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import Sequential\n",
        "from keras.layers import Convolution2D, Dropout, Dense, MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from tabula import read_pdf\n",
        "from pdf2image import convert_from_path"
      ],
      "metadata": {
        "id": "NH4hWVds6KZF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')\n",
        "df = convert_from_path('gdrive/My Drive/DiariosModernos/SemanaAnterior/Nacionales 17 enero.pdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1Qj3LoAiKwc",
        "outputId": "25ad5603-c487-40e1-ade4-30706fd99cb1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = images[0]\n",
        "image = image.convert('RGB')\n",
        "image = image.resize((387, 486))\n",
        "image_array = np.array(image)\n",
        "x = image_array.flatten"
      ],
      "metadata": {
        "id": "KYQ5vRf8wKt8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Integración de modelo pre entrenado VGG-16\n",
        "Este modelo está pre-entrenado por 10,000+ variables de diferentes tipos de datos. Esto nos permite recibir una precisión del modelo final mucho más exacta. Sin embargo, algunos de los datos utilizados para entrenamiento del modelo, deben ser congelados para poder dar espacio a los datos que queremos utilizar nosotros para alimentar al modelo nuevamente. Keras es la librería principal de VGG para esta integración."
      ],
      "metadata": {
        "id": "xyFOHQznWxFc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nzJAIOQl4cj3"
      },
      "outputs": [],
      "source": [
        "Basem = keras.applications.VGG16(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=None,\n",
        "    name=\"VGG16_DiariosModernos\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eo6dk0iwo5bW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}